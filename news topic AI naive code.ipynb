{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"news topic AI naive code.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1qpbTxw5FQNjV9HPDCoLrHTk-j8tJxk3q","authorship_tag":"ABX9TyNovYRS50mG8TSIiH30pWXU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VOYoukFTaMG5"},"source":["**google colab 환경에서 학습을 진행하였습니다.**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CBnFhvaFXb4C","executionInfo":{"status":"ok","timestamp":1628293511431,"user_tz":-540,"elapsed":295,"user":{"displayName":"노원재","photoUrl":"","userId":"04376867334669778985"}},"outputId":"92c09842-9a17-4cfc-cfd0-d19bfd66b350"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eQUNfFgOXemW"},"source":["import os\n","os.chdir('./drive/MyDrive/news topic competition')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xgX7p9UEkuzm"},"source":["import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BIIzIAyPkzi_"},"source":["train_data=pd.read_csv('./data/train_data.csv')\n","topic_dict=pd.read_csv('./data/topic_dict.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":203},"id":"rzLkZVP7l3NB","executionInfo":{"status":"ok","timestamp":1628293515374,"user_tz":-540,"elapsed":8,"user":{"displayName":"노원재","photoUrl":"","userId":"04376867334669778985"}},"outputId":"2c97ed33-fcbb-436a-8ddb-b318cabcbfe1"},"source":["train_data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>title</th>\n","      <th>topic_idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>인천→핀란드 항공기 결항…휴가철 여행객 분통</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>실리콘밸리 넘어서겠다…구글 15조원 들여 美전역 거점화</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>이란 외무 긴장완화 해결책은 미국이 경제전쟁 멈추는 것</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>NYT 클린턴 측근韓기업 특수관계 조명…공과 사 맞물려종합</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>시진핑 트럼프에 중미 무역협상 조속 타결 희망</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   index                             title  topic_idx\n","0      0          인천→핀란드 항공기 결항…휴가철 여행객 분통          4\n","1      1    실리콘밸리 넘어서겠다…구글 15조원 들여 美전역 거점화          4\n","2      2    이란 외무 긴장완화 해결책은 미국이 경제전쟁 멈추는 것          4\n","3      3  NYT 클린턴 측근韓기업 특수관계 조명…공과 사 맞물려종합          4\n","4      4         시진핑 트럼프에 중미 무역협상 조속 타결 희망          4"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"3D865aEImoCO","executionInfo":{"status":"ok","timestamp":1628266190409,"user_tz":-540,"elapsed":16,"user":{"displayName":"노원재","photoUrl":"","userId":"04376867334669778985"}},"outputId":"55d5ffb2-5d10-410a-a5b0-62d450fcc782"},"source":["topic_dict"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>topic</th>\n","      <th>topic_idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>IT과학</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>경제</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>사회</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>생활문화</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>세계</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>스포츠</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>정치</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  topic  topic_idx\n","0  IT과학          0\n","1    경제          1\n","2    사회          2\n","3  생활문화          3\n","4    세계          4\n","5   스포츠          5\n","6    정치          6"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gecNBsQbmWP3","executionInfo":{"status":"ok","timestamp":1628266190410,"user_tz":-540,"elapsed":15,"user":{"displayName":"노원재","photoUrl":"","userId":"04376867334669778985"}},"outputId":"2537a17b-dff6-47bb-affb-433eab574cec"},"source":["train_data['topic_idx'].unique()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([4, 6, 5, 0, 1, 3, 2])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XGjFih3MmIGN","executionInfo":{"status":"ok","timestamp":1628266190827,"user_tz":-540,"elapsed":5,"user":{"displayName":"노원재","photoUrl":"","userId":"04376867334669778985"}},"outputId":"82b0b059-2fb6-4b8b-fd6d-08528a1ba05d"},"source":["topic_dict['topic_idx'].unique()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 2, 3, 4, 5, 6])"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"6-L9V6himgWs"},"source":["- label은 총 0 ~ 6으로 7개를 가지고 있다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3gr7tez_mKpu","executionInfo":{"status":"ok","timestamp":1628266191344,"user_tz":-540,"elapsed":6,"user":{"displayName":"노원재","photoUrl":"","userId":"04376867334669778985"}},"outputId":"6f6a357c-0390-44bb-8095-c5780ea4e380"},"source":["train_data['topic_idx'].value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4    7629\n","2    7362\n","5    6933\n","6    6751\n","1    6222\n","3    5933\n","0    4824\n","Name: topic_idx, dtype: int64"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"8wKPsEXXojj1"},"source":["- label은 대체로 골고루 존재한다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sLLu0VfWmUjP","executionInfo":{"status":"ok","timestamp":1628266195546,"user_tz":-540,"elapsed":3100,"user":{"displayName":"노원재","photoUrl":"","userId":"04376867334669778985"}},"outputId":"62cd2ca1-7ddf-4d42-f384-3ae6698430fc"},"source":["!pip install transformers==4.2.0 sentencepiece"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers==4.2.0 in /usr/local/lib/python3.7/dist-packages (4.2.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.0) (0.0.45)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.0) (4.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.0) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.0) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.0) (21.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.0) (4.41.1)\n","Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.0) (0.9.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.0) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.0) (1.19.5)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.2.0) (3.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.2.0) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.2.0) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.0) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.0) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.0) (1.0.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QlS0mjk-mVC5"},"source":["import torch\n","\n","from sklearn.metrics import accuracy_score\n","from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, Trainer, TrainingArguments, XLMRobertaConfig\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rgxo0JsDmVe_"},"source":["data=pd.read_csv('./data/train_data.csv')\n","\n","# 확인용 데이터 저장\n","#data.to_csv('train_for_confirmation.csv',index=False,encoding='utf-8-sig')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o22U4msg10ri"},"source":["def tokenized_dataset(dataset, tokenizer):\n","    tokenized_sentences = tokenizer(\n","      list(dataset['title']),\n","      return_tensors=\"pt\",\n","      padding=True,\n","      truncation=True,\n","      max_length=44\n","      )\n","    return tokenized_sentences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2B7zIhu_2XWT"},"source":["# Dataset 구성.\n","class news_Dataset(torch.utils.data.Dataset):\n","    def __init__(self, tokenized_dataset, labels):\n","        self.tokenized_dataset = tokenized_dataset\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","    \n","    def get_classes(self):\n","        return self.labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OKZrVmzSK_Ke"},"source":["# load model and tokenizer\n","MODEL_NAME = \"xlm-roberta-large\"\n","tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_NAME)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AZ8Qh0TnK4pS"},"source":["# 기본 20% val set구성\n","train_dataset,val_dataset = train_test_split(data,test_size=0.2,stratify=data['topic_idx'],random_state=42)\n","\n","train_label=train_dataset['topic_idx'].values\n","val_label=val_dataset['topic_idx'].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PmGTQiXO1_5b"},"source":["# tokenizing dataset\n","tokenized_train = tokenized_dataset(train_dataset, tokenizer)\n","tokenized_val = tokenized_dataset(val_dataset, tokenizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GnmBJ_Z7sT12"},"source":["# make dataset for pytorch.\n","news_train_dataset = news_Dataset(tokenized_train, train_label)\n","news_val_dataset = news_Dataset(tokenized_val, val_label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8-YvTHGzzOX"},"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YZrD_3LL3TNq","executionInfo":{"status":"ok","timestamp":1628266223442,"user_tz":-540,"elapsed":18899,"user":{"displayName":"노원재","photoUrl":"","userId":"04376867334669778985"}},"outputId":"9dc31578-5892-4b70-f9a9-bf7d3d4831c3"},"source":["# setting model hyperparameter\n","bert_config = XLMRobertaConfig.from_pretrained(MODEL_NAME)\n","bert_config.num_labels = 7\n","model = XLMRobertaForSequenceClassification.from_pretrained(MODEL_NAME, config=bert_config)\n","model.to(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["XLMRobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n","      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (12): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (13): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (14): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (15): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (16): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (17): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (18): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (19): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (20): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (21): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (22): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (23): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=1024, out_features=7, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"wnlNgCw6bp0X"},"source":["# 파라미터\n","epochs=10\n","lr=1e-5\n","batch_size=32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1e48jr9-QhBH","executionInfo":{"status":"ok","timestamp":1628266223443,"user_tz":-540,"elapsed":39,"user":{"displayName":"노원재","photoUrl":"","userId":"04376867334669778985"}},"outputId":"5fab0920-8985-4866-d223-84c414035629"},"source":["from packaging import version\n","# doc에서의 조건들\n","if isinstance(train_dataset, torch.utils.data.dataset.IterableDataset) :\n","    print('yes')\n","else:\n","    print('no')\n","\n","if version.parse(torch.__version__) >= version.parse(\"1.6\"):\n","    print('if _is_torch_generator_available is True,\\n Use RandomSampler(self.train_dataset, generator=generator)')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["no\n","if _is_torch_generator_available is True,\n"," Use RandomSampler(self.train_dataset, generator=generator)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6WEa7_4pTJoB"},"source":["#https://github.com/huggingface/transformers/blob/83e5a10603ca902c266e40fc98a01dd8a9b04ac4/src/transformers/data/data_collator.py#L38\n","from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n","InputDataClass = NewType(\"InputDataClass\", Any)\n","\n","def default_data_collator(features: List[InputDataClass]) -> Dict[str, torch.Tensor]:\n","    \"\"\"\n","    Very simple data collator that simply collates batches of dict-like objects and performs special handling for\n","    potential keys named:\n","        - ``label``: handles a single value (int or float) per object\n","        - ``label_ids``: handles a list of values per object\n","    Does not do any additional preprocessing: property names of the input object will be used as corresponding inputs\n","    to the model. See glue and ner for example of how it's useful.\n","    \"\"\"\n","\n","    # In this function we'll make the assumption that all `features` in the batch\n","    # have the same attributes.\n","    # So we will look at the first element as a proxy for what attributes exist\n","    # on the whole batch.\n","\n","    # if not isinstance(features[0], (dict, BatchEncoding)):\n","    #     features = [vars(f) for f in features]\n","\n","    #features = [vars(f) for f in features]\n","    first = features[0]\n","    batch = {}\n","\n","    # Special handling for labels.\n","    # Ensure that tensor is created with the correct type\n","    # (it should be automatically the case, but let's make sure of it.)\n","    if \"label\" in first and first[\"label\"] is not None:\n","        label = first[\"label\"].item() if isinstance(first[\"label\"], torch.Tensor) else first[\"label\"]\n","        dtype = torch.long if isinstance(label, int) else torch.float\n","        batch[\"labels\"] = torch.tensor([f[\"label\"] for f in features], dtype=dtype)\n","    elif \"label_ids\" in first and first[\"label_ids\"] is not None:\n","        if isinstance(first[\"label_ids\"], torch.Tensor):\n","            batch[\"labels\"] = torch.stack([f[\"label_ids\"] for f in features])\n","        else:\n","            dtype = torch.long if type(first[\"label_ids\"][0]) is int else torch.float\n","            batch[\"labels\"] = torch.tensor([f[\"label_ids\"] for f in features], dtype=dtype)\n","\n","    # Handling of all other possible keys.\n","    # Again, we will use the first element to figure out which key/values are not None for this model.\n","    for k, v in first.items():\n","        if k not in (\"label\", \"label_ids\") and v is not None and not isinstance(v, str):    # str을 넣어준다.\n","            if isinstance(v, torch.Tensor):\n","                batch[k] = torch.stack([f[k] for f in features])\n","            else:\n","                batch[k] = torch.tensor([f[k] for f in features])\n","\n","    return batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w-XPP3VFZJK4"},"source":["from torch import nn\n","\n","from torch.optim import Optimizer\n","from typing import Callable, Iterable, Optional, Tuple, Union\n","\n","# https://github.com/huggingface/transformers/blob/83e5a10603ca902c266e40fc98a01dd8a9b04ac4/src/transformers/optimization.py#L271\n","class AdamW(Optimizer):\n","    \"\"\"\n","    Implements Adam algorithm with weight decay fix as introduced in `Decoupled Weight Decay Regularization\n","    <https://arxiv.org/abs/1711.05101>`__.\n","    Parameters:\n","        params (:obj:`Iterable[nn.parameter.Parameter]`):\n","            Iterable of parameters to optimize or dictionaries defining parameter groups.\n","        lr (:obj:`float`, `optional`, defaults to 1e-3):\n","            The learning rate to use.\n","        betas (:obj:`Tuple[float,float]`, `optional`, defaults to (0.9, 0.999)):\n","            Adam's betas parameters (b1, b2).\n","        eps (:obj:`float`, `optional`, defaults to 1e-6):\n","            Adam's epsilon for numerical stability.\n","        weight_decay (:obj:`float`, `optional`, defaults to 0):\n","            Decoupled weight decay to apply.\n","        correct_bias (:obj:`bool`, `optional`, defaults to `True`):\n","            Whether or not to correct bias in Adam (for instance, in Bert TF repository they use :obj:`False`).\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        params: Iterable[nn.parameter.Parameter],\n","        lr: float = 1e-3,\n","        betas: Tuple[float, float] = (0.9, 0.999),\n","        eps: float = 1e-6,\n","        weight_decay: float = 0.0,\n","        correct_bias: bool = True,\n","    ):\n","        #require_version(\"torch>=1.5.0\")  # add_ with alpha\n","        if lr < 0.0:\n","            raise ValueError(f\"Invalid learning rate: {lr} - should be >= 0.0\")\n","        if not 0.0 <= betas[0] < 1.0:\n","            raise ValueError(f\"Invalid beta parameter: {betas[0]} - should be in [0.0, 1.0[\")\n","        if not 0.0 <= betas[1] < 1.0:\n","            raise ValueError(f\"Invalid beta parameter: {betas[1]} - should be in [0.0, 1.0[\")\n","        if not 0.0 <= eps:\n","            raise ValueError(f\"Invalid epsilon value: {eps} - should be >= 0.0\")\n","        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, correct_bias=correct_bias)\n","        super().__init__(params, defaults)\n","\n","    def step(self, closure: Callable = None):\n","        \"\"\"\n","        Performs a single optimization step.\n","        Arguments:\n","            closure (:obj:`Callable`, `optional`): A closure that reevaluates the model and returns the loss.\n","        \"\"\"\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","            for p in group[\"params\"]:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad.data\n","                if grad.is_sparse:\n","                    raise RuntimeError(\"Adam does not support sparse gradients, please consider SparseAdam instead\")\n","\n","                state = self.state[p]\n","\n","                # State initialization\n","                if len(state) == 0:\n","                    state[\"step\"] = 0\n","                    # Exponential moving average of gradient values\n","                    state[\"exp_avg\"] = torch.zeros_like(p.data)\n","                    # Exponential moving average of squared gradient values\n","                    state[\"exp_avg_sq\"] = torch.zeros_like(p.data)\n","\n","                exp_avg, exp_avg_sq = state[\"exp_avg\"], state[\"exp_avg_sq\"]\n","                beta1, beta2 = group[\"betas\"]\n","\n","                state[\"step\"] += 1\n","\n","                # Decay the first and second moment running average coefficient\n","                # In-place operations to update the averages at the same time\n","                exp_avg.mul_(beta1).add_(grad, alpha=(1.0 - beta1))\n","                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1.0 - beta2)\n","                denom = exp_avg_sq.sqrt().add_(group[\"eps\"])\n","\n","                step_size = group[\"lr\"]\n","                if group[\"correct_bias\"]:  # No bias correction for Bert\n","                    bias_correction1 = 1.0 - beta1 ** state[\"step\"]\n","                    bias_correction2 = 1.0 - beta2 ** state[\"step\"]\n","                    step_size = step_size * math.sqrt(bias_correction2) / bias_correction1\n","\n","                p.data.addcdiv_(exp_avg, denom, value=-step_size)\n","\n","                # Just adding the square of the weights to the loss function is *not*\n","                # the correct way of using L2 regularization/weight decay with Adam,\n","                # since that will interact with the m and v parameters in strange ways.\n","                #\n","                # Instead we want to decay the weights in a manner that doesn't interact\n","                # with the m/v parameters. This is equivalent to adding the square\n","                # of the weights to the loss with plain (non-momentum) SGD.\n","                # Add weight decay at the end (fixed version)\n","                if group[\"weight_decay\"] > 0.0:\n","                    p.data.add_(p.data, alpha=(-group[\"lr\"] * group[\"weight_decay\"]))\n","\n","        return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nv-oDgUqGkuC"},"source":["def get_parameter_names(model, forbidden_layer_types):\n","    \"\"\"\n","    Returns the names of the model parameters that are not inside a forbidden layer.\n","    \"\"\"\n","    result = []\n","    for name, child in model.named_children():\n","        result += [\n","            f\"{name}.{n}\"\n","            for n in get_parameter_names(child, forbidden_layer_types)\n","            if not isinstance(child, tuple(forbidden_layer_types))\n","        ]\n","    # Add model specific parameters (defined with nn.Parameter) since they are not in any child.\n","    result += list(model._parameters.keys())\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5_VXXJ_6YfYC"},"source":["def create_optimizer(model):\n","        \"\"\"\n","        Setup the optimizer.\n","\n","        We provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the\n","        Trainer's init through :obj:`optimizers`, or subclass and override this method in a subclass.\n","        \"\"\"\n","        decay_parameters = get_parameter_names(model, [nn.LayerNorm])\n","        decay_parameters = [name for name in decay_parameters if \"bias\" not in name]\n","        optimizer_grouped_parameters = [\n","            {\n","                \"params\": [p for n, p in model.named_parameters() if n in decay_parameters],\n","                \"weight_decay\": 0.01,\n","            },\n","            {\n","                \"params\": [p for n, p in model.named_parameters() if n not in decay_parameters],\n","                \"weight_decay\": 0.0,\n","            },\n","        ]\n","\n","        optimizer_cls = AdamW\n","        optimizer_kwargs = {\n","            \"betas\": (0.9, 0.999),\n","            \"eps\": 1e-8,\n","        }\n","        optimizer_kwargs[\"lr\"] = lr\n","        return optimizer_cls(optimizer_grouped_parameters, **optimizer_kwargs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nL3dKMBIbNY6"},"source":["from torch.optim.lr_scheduler import LambdaLR\n","\n","def get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, last_epoch=-1):\n","    \"\"\"\n","    Create a schedule with a learning rate that decreases linearly from the initial lr set in the optimizer to 0, after\n","    a warmup period during which it increases linearly from 0 to the initial lr set in the optimizer.\n","    Args:\n","        optimizer (:class:`~torch.optim.Optimizer`):\n","            The optimizer for which to schedule the learning rate.\n","        num_warmup_steps (:obj:`int`):\n","            The number of steps for the warmup phase.\n","        num_training_steps (:obj:`int`):\n","            The total number of training steps.\n","        last_epoch (:obj:`int`, `optional`, defaults to -1):\n","            The index of the last epoch when resuming training.\n","    Return:\n","        :obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n","    \"\"\"\n","\n","    def lr_lambda(current_step: int):\n","        if current_step < num_warmup_steps:\n","            return float(current_step) / float(max(1, num_warmup_steps))\n","        return max(\n","            0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps))\n","        )\n","\n","    return LambdaLR(optimizer, lr_lambda, last_epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TFAkXzrSgdJc"},"source":["# loss\n","from dataclasses import dataclass\n","\n","@dataclass\n","class LabelSmoother:\n","    \"\"\"\n","    Adds label-smoothing on a pre-computed output from a Transformers model.\n","    Args:\n","        epsilon (:obj:`float`, `optional`, defaults to 0.1):\n","            The label smoothing factor.\n","        ignore_index (:obj:`int`, `optional`, defaults to -100):\n","            The index in the labels to ignore when computing the loss.\n","    \"\"\"\n","\n","    epsilon: float = 0.1\n","    ignore_index: int = -100\n","\n","    def __call__(self, model_output, labels):\n","        logits = model_output[\"logits\"] if isinstance(model_output, dict) else model_output[0]\n","        log_probs = -nn.functional.log_softmax(logits, dim=-1)\n","        if labels.dim() == log_probs.dim() - 1:\n","            labels = labels.unsqueeze(-1)\n","\n","        padding_mask = labels.eq(self.ignore_index)\n","        # In case the ignore_index is -100, the gather will fail, so we replace labels by 0. The padding_mask\n","        # will ignore them in any case.\n","        labels.clamp_min_(0)\n","        nll_loss = log_probs.gather(dim=-1, index=labels)\n","        # works for fp16 input tensor too, by internally upcasting it to fp32\n","        smoothed_loss = log_probs.sum(dim=-1, keepdim=True, dtype=torch.float32)\n","\n","        nll_loss.masked_fill_(padding_mask, 0.0)\n","        smoothed_loss.masked_fill_(padding_mask, 0.0)\n","\n","        # Take the mean over the label dimensions, then divide by the number of active elements (i.e. not-padded):\n","        num_active_elements = padding_mask.numel() - padding_mask.long().sum()\n","        nll_loss = nll_loss.sum() / num_active_elements\n","        smoothed_loss = smoothed_loss.sum() / (num_active_elements * log_probs.shape[-1])\n","        return (1 - self.epsilon) * nll_loss + self.epsilon * smoothed_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AXnhiJv043NJ"},"source":["import math\n","\n","from torch.utils.data import DataLoader\n","from torch.utils.data.sampler import RandomSampler, SequentialSampler\n","from tqdm import tqdm\n","\n","# https://huggingface.co/transformers/_modules/transformers/trainer.html#Trainer\n","\n","# loader에 필요한 인자들\n","data_collator = default_data_collator\n","\n","# sampler에 사용 인자 \n","generator = torch.Generator()\n","generator.manual_seed(int(torch.empty((), dtype=torch.int64).random_().item()))\n","\n","# sampler 정의\n","train_sampler=RandomSampler(train_dataset, generator=generator)\n","eval_sampler= SequentialSampler(val_dataset)\n","\n","train_dataloader = DataLoader(\n","            news_train_dataset,\n","            batch_size=batch_size,\n","            sampler= train_sampler,\n","            collate_fn= data_collator,\n","            drop_last=False,\n","            num_workers=4,\n","            pin_memory=True,\n","        )\n","val_dataloader = DataLoader(\n","            news_val_dataset,\n","            batch_size=batch_size,\n","            sampler=eval_sampler,\n","            collate_fn= data_collator,\n","            drop_last=False,\n","            num_workers=4,\n","            pin_memory=True,\n","        )\n","\n","num_update_steps_per_epoch = max(len(train_dataloader), 1)\n","max_steps = math.ceil(epochs * num_update_steps_per_epoch)\n","\n","# criterion, optimizer, scheduler 설정\n","criterion=LabelSmoother(epsilon=0.2)\n","optimizer = create_optimizer(model)\n","scheduler = get_linear_schedule_with_warmup(\n","        optimizer=optimizer,\n","        num_warmup_steps=5000,\n","        num_training_steps=max_steps\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BIUx6saQEFIn"},"source":["def ids_to_string(ids_list):\n","  return tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(ids_list,skip_special_tokens=True))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59J74B0WMTgD","executionInfo":{"status":"ok","timestamp":1628272917322,"user_tz":-540,"elapsed":5603943,"user":{"displayName":"노원재","photoUrl":"","userId":"04376867334669778985"}},"outputId":"a85b403e-2462-4cfe-9a3e-a3a401a80105"},"source":["import warnings\n","warnings.filterwarnings(action='ignore')\n","\n","print_step=250\n","print (\"Start training.\\n\")\n","for epoch in tqdm(range(epochs)):\n","    print(f'{epoch+1} epoch Training...')\n","    # train mode\n","    model.train()\n","    train_loss=0\n","    train_acc=0\n","    val_loss=0\n","    val_acc=0\n","\n","    for step, inputs in enumerate(train_dataloader):\n","        outputs = model(\n","              input_ids=inputs['input_ids'].to(device),\n","              attention_mask=inputs['attention_mask'].to(device)\n","              )\n","        \n","        loss = criterion(outputs,inputs['labels'].to(device))\n","\n","        optimizer.zero_grad() # reset gradient \n","        loss.backward() # back propagation  \n","        optimizer.step() # parameters update\n","        scheduler.step() # scheduler step\n","        \n","        labels = inputs['labels'].detach().cpu().numpy()\n","        preds = outputs['logits'].argmax(-1).detach().cpu().numpy()\n","\n","        # 정확도 계산\n","        train_acc += sum(labels == preds)\n","\n","        # loss 계산\n","        train_loss += loss.item() * inputs['input_ids'].shape[0]\n","\n","        # step 주기에 따른 loss 출력\n","        if (step + 1) % print_step == 0:\n","            print(f'Epoch [{epoch+1}/{epochs}], Step [{step+1}/{len(train_dataloader)}], Loss: {loss.item():.2f}, acc: {train_acc/((step+1)*batch_size):.4f}')\n","    \n","    # metric 계산\n","    train_loss = train_loss / len(news_train_dataset)\n","    train_acc = train_acc / len(news_train_dataset)\n","\n","    # val mode\n","    print (\"Start validation.\\n\")\n","    model.eval()\n","\n","    # 잘못 예측한 데이터 저장\n","    err_data={'title':[],'preds':[],'labels':[]}\n","    with torch.no_grad():\n","        for step, inputs in enumerate(val_dataloader):\n","            outputs = model(\n","              input_ids=inputs['input_ids'].to(device),\n","              attention_mask=inputs['attention_mask'].to(device)\n","              )\n","        \n","            loss = criterion(outputs,inputs['labels'].to(device))\n","            \n","            labels = inputs['labels'].detach().cpu().numpy()\n","            preds = outputs['logits'].argmax(-1).detach().cpu().numpy()\n","\n","            # 정확도 계산\n","            val_acc += sum(labels == preds)\n","\n","            # loss 계산\n","            val_loss += loss.item() * inputs['input_ids'].shape[0]\n","\n","            # csv 만들기\n","            ids_list=inputs['input_ids'][~(labels == preds)].detach().cpu().numpy()\n","            err_data['title'].extend(list(map(ids_to_string,ids_list)))\n","            err_data['preds'].extend(preds[~(labels == preds)])\n","            err_data['labels'].extend(labels[~(labels == preds)])\n","\n","        # metric 계산\n","        val_loss = val_loss / len(news_val_dataset)\n","        val_acc = val_acc / len(news_val_dataset)\n","    print('err_data Save...')\n","    pd.DataFrame(err_data).to_csv(f'./results/err_data{epoch+1}.csv',encoding='utf-8-sig',index=False)\n","    print(f'Epoch: [{epoch+1}] Train Loss: [{train_loss:.4f}] Train Acc: [{train_acc:.4f}] Val Loss: [{val_loss:.4f}] Val Acc:[{val_acc:.4f}] ')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Start training.\n","\n","1 epoch Training...\n","Epoch [1/10], Step [250/1142], Loss: 1.03, acc: 0.8625\n","Epoch [1/10], Step [500/1142], Loss: 1.08, acc: 0.8666\n","Epoch [1/10], Step [750/1142], Loss: 1.21, acc: 0.8682\n","Epoch [1/10], Step [1000/1142], Loss: 0.88, acc: 0.8683\n","Start validation.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 10%|█         | 1/10 [09:20<1:24:05, 560.59s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["err_data Save...\n","Epoch: [1] Train Loss: [0.9979] Train Acc: [0.8690] Val Loss: [0.9718] Val Acc:[0.8833] \n","2 epoch Training...\n","Epoch [2/10], Step [250/1142], Loss: 0.95, acc: 0.8851\n","Epoch [2/10], Step [500/1142], Loss: 1.03, acc: 0.8829\n","Epoch [2/10], Step [750/1142], Loss: 0.94, acc: 0.8821\n","Epoch [2/10], Step [1000/1142], Loss: 1.00, acc: 0.8815\n","Start validation.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 20%|██        | 2/10 [18:40<1:14:43, 560.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["err_data Save...\n","Epoch: [2] Train Loss: [0.9721] Train Acc: [0.8820] Val Loss: [0.9632] Val Acc:[0.8852] \n","3 epoch Training...\n","Epoch [3/10], Step [250/1142], Loss: 0.97, acc: 0.8948\n","Epoch [3/10], Step [500/1142], Loss: 1.10, acc: 0.8948\n","Epoch [3/10], Step [750/1142], Loss: 1.04, acc: 0.8937\n","Epoch [3/10], Step [1000/1142], Loss: 1.05, acc: 0.8898\n","Start validation.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 30%|███       | 3/10 [28:00<1:05:22, 560.39s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["err_data Save...\n","Epoch: [3] Train Loss: [0.9585] Train Acc: [0.8901] Val Loss: [0.9601] Val Acc:[0.8879] \n","4 epoch Training...\n","Epoch [4/10], Step [250/1142], Loss: 0.81, acc: 0.9075\n","Epoch [4/10], Step [500/1142], Loss: 0.95, acc: 0.9042\n","Epoch [4/10], Step [750/1142], Loss: 0.90, acc: 0.9045\n","Epoch [4/10], Step [1000/1142], Loss: 0.95, acc: 0.9025\n","Start validation.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 40%|████      | 4/10 [37:21<56:01, 560.29s/it]  \u001b[A"],"name":"stderr"},{"output_type":"stream","text":["err_data Save...\n","Epoch: [4] Train Loss: [0.9360] Train Acc: [0.9022] Val Loss: [0.9572] Val Acc:[0.8892] \n","5 epoch Training...\n","Epoch [5/10], Step [250/1142], Loss: 0.91, acc: 0.9180\n","Epoch [5/10], Step [500/1142], Loss: 0.84, acc: 0.9185\n","Epoch [5/10], Step [750/1142], Loss: 0.86, acc: 0.9166\n","Epoch [5/10], Step [1000/1142], Loss: 0.93, acc: 0.9163\n","Start validation.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 50%|█████     | 5/10 [46:41<46:41, 560.22s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["err_data Save...\n","Epoch: [5] Train Loss: [0.9127] Train Acc: [0.9166] Val Loss: [0.9589] Val Acc:[0.8907] \n","6 epoch Training...\n","Epoch [6/10], Step [250/1142], Loss: 0.86, acc: 0.9364\n","Epoch [6/10], Step [500/1142], Loss: 0.80, acc: 0.9346\n","Epoch [6/10], Step [750/1142], Loss: 0.91, acc: 0.9308\n","Epoch [6/10], Step [1000/1142], Loss: 0.83, acc: 0.9313\n","Start validation.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 60%|██████    | 6/10 [56:01<37:20, 560.21s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["err_data Save...\n","Epoch: [6] Train Loss: [0.8876] Train Acc: [0.9318] Val Loss: [0.9638] Val Acc:[0.8897] \n","7 epoch Training...\n","Epoch [7/10], Step [250/1142], Loss: 0.91, acc: 0.9479\n","Epoch [7/10], Step [500/1142], Loss: 0.85, acc: 0.9481\n","Epoch [7/10], Step [750/1142], Loss: 0.80, acc: 0.9481\n","Epoch [7/10], Step [1000/1142], Loss: 1.01, acc: 0.9477\n","Start validation.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 70%|███████   | 7/10 [1:05:21<28:00, 560.30s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["err_data Save...\n","Epoch: [7] Train Loss: [0.8643] Train Acc: [0.9467] Val Loss: [0.9676] Val Acc:[0.8909] \n","8 epoch Training...\n","Epoch [8/10], Step [250/1142], Loss: 0.79, acc: 0.9587\n","Epoch [8/10], Step [500/1142], Loss: 0.92, acc: 0.9583\n","Epoch [8/10], Step [750/1142], Loss: 0.87, acc: 0.9594\n","Epoch [8/10], Step [1000/1142], Loss: 0.85, acc: 0.9595\n","Start validation.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 80%|████████  | 8/10 [1:14:42<18:40, 560.35s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["err_data Save...\n","Epoch: [8] Train Loss: [0.8437] Train Acc: [0.9591] Val Loss: [0.9749] Val Acc:[0.8876] \n","9 epoch Training...\n","Epoch [9/10], Step [250/1142], Loss: 0.80, acc: 0.9692\n","Epoch [9/10], Step [500/1142], Loss: 0.84, acc: 0.9679\n","Epoch [9/10], Step [750/1142], Loss: 0.94, acc: 0.9690\n","Epoch [9/10], Step [1000/1142], Loss: 0.79, acc: 0.9688\n","Start validation.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 90%|█████████ | 9/10 [1:24:02<09:20, 560.45s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["err_data Save...\n","Epoch: [9] Train Loss: [0.8294] Train Acc: [0.9689] Val Loss: [0.9788] Val Acc:[0.8879] \n","10 epoch Training...\n","Epoch [10/10], Step [250/1142], Loss: 0.80, acc: 0.9694\n","Epoch [10/10], Step [500/1142], Loss: 0.77, acc: 0.9722\n","Epoch [10/10], Step [750/1142], Loss: 0.79, acc: 0.9722\n","Epoch [10/10], Step [1000/1142], Loss: 0.86, acc: 0.9716\n","Start validation.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 10/10 [1:33:23<00:00, 560.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["err_data Save...\n","Epoch: [10] Train Loss: [0.8241] Train Acc: [0.9714] Val Loss: [0.9788] Val Acc:[0.8879] \n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"dqmNsblLze7l"},"source":["## err file 확인하기\n","- 모델이 정답 label말고 어떠한 label로 예측했는지 시각화"]},{"cell_type":"code","metadata":{"id":"J5PgwxhT6SkR"},"source":["# 나눔 고딕 install\n","!apt-get update -qq\n","!apt-get install fonts-nanum* -qq"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VcDFnX6b6F7H"},"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","import matplotlib.font_manager as fm  # 폰트 관련 용도\n","\n","sns.set_theme(style=\"darkgrid\")\n","\n","# 시스템에 설치된 폰트 확인\n","sys_font=fm.findSystemFonts()\n","print(f\"sys_font number: {len(sys_font)}\")\n","print(sys_font)\n","\n","nanum_font = [f for f in sys_font if 'Nanum' in f]\n","print(f\"nanum_font number: {len(nanum_font)}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Yn-B5Ur6MId"},"source":["# 폰트 개수 확인\n","sys_font=fm.findSystemFonts()\n","print(f\"sys_font number: {len(sys_font)}\")\n","\n","nanum_font = [f for f in sys_font if 'Nanum' in f]\n","print(f\"nanum_font number: {len(nanum_font)}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JcXatOph6QRN"},"source":["# 설치 된것중 하나 선택\n","path = '/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf'  # 설치된 나눔글꼴중 원하는 녀석의 전체 경로를 가져오자\n","font_name = fm.FontProperties(fname=path, size=10).get_name()\n","\n","# 우선 fm._rebuild()\n","fm._rebuild()\n","\n","print(font_name)\n","plt.rc('font', family=font_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"89s37nxAtH1f"},"source":["err=pd.read_csv('./results/err_data7.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gqyqnsJPtQzS","executionInfo":{"status":"ok","timestamp":1628294445905,"user_tz":-540,"elapsed":14,"user":{"displayName":"노원재","photoUrl":"","userId":"04376867334669778985"}},"outputId":"9051510b-f2a9-4b8a-8235-eaf3afffc2cd"},"source":["err['labels'].value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2    349\n","1    191\n","3    126\n","0    120\n","6    115\n","4     95\n","5     28\n","Name: labels, dtype: int64"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"CBau5ngovOoD"},"source":["topic=pd.read_csv('./data/topic_dict.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"rXYP_1qqv0hR","executionInfo":{"status":"ok","timestamp":1628294447122,"user_tz":-540,"elapsed":8,"user":{"displayName":"노원재","photoUrl":"","userId":"04376867334669778985"}},"outputId":"15743bef-33f8-4826-f6cc-52596a1d1158"},"source":["topic"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>topic</th>\n","      <th>topic_idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>IT과학</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>경제</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>사회</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>생활문화</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>세계</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>스포츠</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>정치</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  topic  topic_idx\n","0  IT과학          0\n","1    경제          1\n","2    사회          2\n","3  생활문화          3\n","4    세계          4\n","5   스포츠          5\n","6    정치          6"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"5O56_7uav9yk"},"source":["topic_dict={col['topic_idx']: col['topic'] for index,col in topic.iterrows()}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XsM9OYwBxq0Y"},"source":["def idx_to_topic(x):\n","  x['preds']=topic_dict[x['preds']]\n","  x['labels']=topic_dict[x['labels']]\n","  return x\n","\n","err=err.apply(idx_to_topic, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":410},"id":"ZisOVMG46ZU2","executionInfo":{"status":"ok","timestamp":1628294458288,"user_tz":-540,"elapsed":1008,"user":{"displayName":"노원재","photoUrl":"","userId":"04376867334669778985"}},"outputId":"c65e4ae8-87be-4904-f0f6-886b3b59451d"},"source":["plt.figure(figsize=(12,6))\n","sns.countplot(x=\"labels\",hue='preds', data=err)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f5909caa850>"]},"metadata":{"tags":[]},"execution_count":36},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"utKk_c5433pU","executionInfo":{"status":"ok","timestamp":1628294597052,"user_tz":-540,"elapsed":338,"user":{"displayName":"노원재","photoUrl":"","userId":"04376867334669778985"}},"outputId":"7083d0f7-5ed6-4d34-f457-d0f5250631bf"},"source":["err.head(50)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>preds</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>방송소식 EBS 방을 구해드립니다 내일 첫 방송 外</td>\n","      <td>생활문화</td>\n","      <td>사회</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>美 금리인상 속도전 우려에 원달러 환율 14.2원 급등</td>\n","      <td>세계</td>\n","      <td>경제</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>넷플릭스 CCO 한국 콘텐츠 코로나 예방하며 제작</td>\n","      <td>IT과학</td>\n","      <td>생활문화</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>SNS돋보기 이통3사 통신비 인하 반대...대기업 횡포 비판</td>\n","      <td>사회</td>\n","      <td>IT과학</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>에쓰오일 여성고객 대상 구도일패밀리 응원이벤트</td>\n","      <td>사회</td>\n","      <td>생활문화</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>영암 월출산 국립공원 지정 30주년 기념식</td>\n","      <td>생활문화</td>\n","      <td>사회</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>한산한 대학 캠퍼스</td>\n","      <td>생활문화</td>\n","      <td>사회</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>LG화학 등 120개 상장사 3월 셋째주 정기 주총</td>\n","      <td>경제</td>\n","      <td>사회</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>일본에 빠진 한국인...일본 방문 해외관광객에서 중국 제치고 1위</td>\n","      <td>생활문화</td>\n","      <td>사회</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>현대카드 2531일 유명 레스토랑 50% 할인 고메위크</td>\n","      <td>생활문화</td>\n","      <td>경제</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>권익위 전원위원회</td>\n","      <td>사회</td>\n","      <td>정치</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11월 9일은 소방의 날...소방청 제56회 기념식 개최</td>\n","      <td>사회</td>\n","      <td>생활문화</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>伊 오성운동 당원 연정안 가결...좌파 포퓰리즘 연정 눈앞</td>\n","      <td>정치</td>\n","      <td>세계</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>태풍 링링 러시아 블라디보스토크 인근서 소멸</td>\n","      <td>세계</td>\n","      <td>생활문화</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>국제현대무용제 이해준 운영위원장</td>\n","      <td>생활문화</td>\n","      <td>사회</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>영상 통신3사 차세대 5G 서비스 다음 달 세계 첫 개시</td>\n","      <td>IT과학</td>\n","      <td>경제</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>日·臺 프리미어12 개막전서 베네수·푸에르토 제압</td>\n","      <td>스포츠</td>\n","      <td>세계</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>전남 침수·가로수 피해 속출...호우특보 모두 해제종합</td>\n","      <td>생활문화</td>\n","      <td>사회</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>김종인오자와 전 간사장 회동</td>\n","      <td>사회</td>\n","      <td>정치</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>정지선 현대百그룹 회장 새로운 10년 위한 출발점이자 전환점</td>\n","      <td>사회</td>\n","      <td>경제</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>세부퍼시픽 사전 주문 기내식 메뉴 12종 출시</td>\n","      <td>생활문화</td>\n","      <td>경제</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>독도로 출발하기 전 기념촬영 하는 독도아카데미 대학생</td>\n","      <td>사회</td>\n","      <td>생활문화</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>산천어축제 창작썰매 경주 진짜 이기고 싶다</td>\n","      <td>스포츠</td>\n","      <td>생활문화</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>올해 8월 방한관광객 26.1% 증가...중국 40.9%↑</td>\n","      <td>경제</td>\n","      <td>생활문화</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>영상 국민연금 월평균 5천970원 더 받는다...물가 반영</td>\n","      <td>사회</td>\n","      <td>경제</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>개인 전문투자자 요건 완화...혁신기업 투자세력 육성</td>\n","      <td>경제</td>\n","      <td>사회</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>3월 9일 전국서 부분일식...해 10% 미만 가려져</td>\n","      <td>사회</td>\n","      <td>IT과학</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>MB 법정으로</td>\n","      <td>정치</td>\n","      <td>사회</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>이통 3사 원가보상률 100% 넘겨...요금인하 여력 충분</td>\n","      <td>경제</td>\n","      <td>IT과학</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>김관영 음주운전 방지장치 설치 시 세제혜택 법안 추진</td>\n","      <td>사회</td>\n","      <td>정치</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>언론진흥재단 버스·택시 승강장 광고매체 전자지도 개발</td>\n","      <td>IT과학</td>\n","      <td>사회</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>게시판 한국원자력학회 2016춘계학술발표회 개최</td>\n","      <td>IT과학</td>\n","      <td>사회</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>인니 지자체 빈곤 지원 때 가난한 집 붉은 페인트칠 논란</td>\n","      <td>세계</td>\n","      <td>사회</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>올림픽 北매체 아직 조용...기대 이하 성적 때문</td>\n","      <td>스포츠</td>\n","      <td>정치</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>LG전자 G6 후속모델 준비됐을 때 출시...상반기 중 예상종합2보</td>\n","      <td>IT과학</td>\n","      <td>경제</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>日학자들의 제국의 위안부 변론...논쟁 아닌 대화 위한 책</td>\n","      <td>생활문화</td>\n","      <td>세계</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>마리 국립현대미술관장 물러난다...10월초 공모</td>\n","      <td>생활문화</td>\n","      <td>사회</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>잠자던 동전 346억원어치 지폐로 재탄생</td>\n","      <td>경제</td>\n","      <td>사회</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>홍남기 내년 1분기까지 최저임금 결정구조 개편방안 마련속보</td>\n","      <td>사회</td>\n","      <td>정치</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>그래픽 인터넷 DA·동영상 광고 매출 현황</td>\n","      <td>사회</td>\n","      <td>경제</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>MBN 노조 부동산 물적분할 중단하고 소유경영 분리해야</td>\n","      <td>경제</td>\n","      <td>사회</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>민주노총 청년노동자 직장 내 괴롭힘으로 숨져...관계자 처벌</td>\n","      <td>사회</td>\n","      <td>정치</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>위민크로스DMZ 28일 남북 평화기원 걷기행사</td>\n","      <td>생활문화</td>\n","      <td>정치</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>기념촬영 마친 각국 정상들</td>\n","      <td>정치</td>\n","      <td>세계</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>원로학자의 식민지근대화론 반박 일제 토지조사는 수탈</td>\n","      <td>생활문화</td>\n","      <td>사회</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>김정주 넥슨 등기이사 사임...평생 잘못 지고 살아갈 것</td>\n","      <td>사회</td>\n","      <td>경제</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>개성공단기업에 휴업·휴직수당...지방투자촉진보조금 확대종합</td>\n","      <td>정치</td>\n","      <td>경제</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>제29회 민족민주열사희생자 범국민추모제</td>\n","      <td>사회</td>\n","      <td>생활문화</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>인스타그램에서 쇼핑한다...사진 속 태그 누르면 연결종합</td>\n","      <td>IT과학</td>\n","      <td>생활문화</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>망원시장 찾은 이재갑 고용부 장관</td>\n","      <td>사회</td>\n","      <td>정치</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                    title preds labels\n","0            방송소식 EBS 방을 구해드립니다 내일 첫 방송 外  생활문화     사회\n","1          美 금리인상 속도전 우려에 원달러 환율 14.2원 급등    세계     경제\n","2             넷플릭스 CCO 한국 콘텐츠 코로나 예방하며 제작  IT과학   생활문화\n","3       SNS돋보기 이통3사 통신비 인하 반대...대기업 횡포 비판    사회   IT과학\n","4               에쓰오일 여성고객 대상 구도일패밀리 응원이벤트    사회   생활문화\n","5                 영암 월출산 국립공원 지정 30주년 기념식  생활문화     사회\n","6                              한산한 대학 캠퍼스  생활문화     사회\n","7            LG화학 등 120개 상장사 3월 셋째주 정기 주총    경제     사회\n","8    일본에 빠진 한국인...일본 방문 해외관광객에서 중국 제치고 1위  생활문화     사회\n","9          현대카드 2531일 유명 레스토랑 50% 할인 고메위크  생활문화     경제\n","10                              권익위 전원위원회    사회     정치\n","11        11월 9일은 소방의 날...소방청 제56회 기념식 개최    사회   생활문화\n","12       伊 오성운동 당원 연정안 가결...좌파 포퓰리즘 연정 눈앞    정치     세계\n","13               태풍 링링 러시아 블라디보스토크 인근서 소멸    세계   생활문화\n","14                      국제현대무용제 이해준 운영위원장  생활문화     사회\n","15        영상 통신3사 차세대 5G 서비스 다음 달 세계 첫 개시  IT과학     경제\n","16            日·臺 프리미어12 개막전서 베네수·푸에르토 제압   스포츠     세계\n","17         전남 침수·가로수 피해 속출...호우특보 모두 해제종합  생활문화     사회\n","18                        김종인오자와 전 간사장 회동    사회     정치\n","19      정지선 현대百그룹 회장 새로운 10년 위한 출발점이자 전환점    사회     경제\n","20              세부퍼시픽 사전 주문 기내식 메뉴 12종 출시  생활문화     경제\n","21          독도로 출발하기 전 기념촬영 하는 독도아카데미 대학생    사회   생활문화\n","22                산천어축제 창작썰매 경주 진짜 이기고 싶다   스포츠   생활문화\n","23       올해 8월 방한관광객 26.1% 증가...중국 40.9%↑    경제   생활문화\n","24       영상 국민연금 월평균 5천970원 더 받는다...물가 반영    사회     경제\n","25          개인 전문투자자 요건 완화...혁신기업 투자세력 육성    경제     사회\n","26          3월 9일 전국서 부분일식...해 10% 미만 가려져    사회   IT과학\n","27                                MB 법정으로    정치     사회\n","28       이통 3사 원가보상률 100% 넘겨...요금인하 여력 충분    경제   IT과학\n","29          김관영 음주운전 방지장치 설치 시 세제혜택 법안 추진    사회     정치\n","30          언론진흥재단 버스·택시 승강장 광고매체 전자지도 개발  IT과학     사회\n","31             게시판 한국원자력학회 2016춘계학술발표회 개최  IT과학     사회\n","32        인니 지자체 빈곤 지원 때 가난한 집 붉은 페인트칠 논란    세계     사회\n","33            올림픽 北매체 아직 조용...기대 이하 성적 때문   스포츠     정치\n","34  LG전자 G6 후속모델 준비됐을 때 출시...상반기 중 예상종합2보  IT과학     경제\n","35       日학자들의 제국의 위안부 변론...논쟁 아닌 대화 위한 책  생활문화     세계\n","36             마리 국립현대미술관장 물러난다...10월초 공모  생활문화     사회\n","37                 잠자던 동전 346억원어치 지폐로 재탄생    경제     사회\n","38       홍남기 내년 1분기까지 최저임금 결정구조 개편방안 마련속보    사회     정치\n","39                그래픽 인터넷 DA·동영상 광고 매출 현황    사회     경제\n","40         MBN 노조 부동산 물적분할 중단하고 소유경영 분리해야    경제     사회\n","41      민주노총 청년노동자 직장 내 괴롭힘으로 숨져...관계자 처벌    사회     정치\n","42              위민크로스DMZ 28일 남북 평화기원 걷기행사  생활문화     정치\n","43                         기념촬영 마친 각국 정상들    정치     세계\n","44           원로학자의 식민지근대화론 반박 일제 토지조사는 수탈  생활문화     사회\n","45        김정주 넥슨 등기이사 사임...평생 잘못 지고 살아갈 것    사회     경제\n","46       개성공단기업에 휴업·휴직수당...지방투자촉진보조금 확대종합    정치     경제\n","47                  제29회 민족민주열사희생자 범국민추모제    사회   생활문화\n","48        인스타그램에서 쇼핑한다...사진 속 태그 누르면 연결종합  IT과학   생활문화\n","49                     망원시장 찾은 이재갑 고용부 장관    사회     정치"]},"metadata":{"tags":[]},"execution_count":37}]}]}